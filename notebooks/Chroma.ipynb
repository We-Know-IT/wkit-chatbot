{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data to documents\n",
    "This notebook is for using the data we obtained in the dataframe and representing it in a langchain Document object. This is a data structure very applicable to Data Science and NLP tasks, since it allows us to separate the actual text content we want to use for our embeddings from the metadata tags, such as source and url. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Importing essential packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "import sys\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Loading the df from memory\n",
    "\n",
    "Since we already extracted the data in the scraping notebook, we can just load it from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - The langchain Document\n",
    "\n",
    "Now, the idea behind this data structure is that it is very suitable for NLP tasks. It has one attribute, page_content, that is the plain text we intend to embed and store in a vectorized form. Additionally, it has a metadata field which is a customizable dictionary where we can store whatever we want. This content is not touched by the embedding model, so we can use this downstream for filtering etc.\n",
    "\n",
    "This function simply loops through the dataframe and builds a Document instance. This is where you would typically introduce as much metadata as you can find, since it is cheap in terms of storage and gives you much more dynamic possibilities in future alterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_to_langchain_documents(df):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame into a list of LangChain Document objects.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to convert.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of LangChain Document objects.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for _, row in df.iterrows():\n",
    "        doc = Document(\n",
    "            page_content=row['text'],\n",
    "            metadata={\n",
    "                'key': row['key'],\n",
    "                'url': row['url'],\n",
    "                'category': row['category']\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_to_langchain_documents(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - A glance at the Documents\n",
    "Just have a quick look at the document we print out. You can see that it has the `page_content` being the text we want to vectorize, and then in the end we have our customized `metadata` dictionary. Perfect setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Nyfiken På We Know IT? | Om Oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Varför We Know IT? Vi är IT-konsultbolaget som satsar på studerande och nyexade talanger med höga ambitioner och drivkrafter.\\xa0Experter på utveckling, design och digital strategi, We Know IT helt enkelt. \\u200bMål, vision & sådant gött Vårt mål är att vara det självklara valet för studenter att starta sin karriär på, och det självklara valet för företag som behöver motiverad och innovativ kompetens. Det är inte alla som får chansen att jobba med morgondagens skarpaste konsulter. Vi får det varje dag, och du som kund eller samarbetspartner får stora möjligheter genom att välja oss. Vi vill ha kul på vägen och leverera över förväntan så ofta som möjligt. Det gör vi genom att vara lyhörda, ha öppen kommunikation och starka relationer. Vi ger våra WKITare frihet och tror på varje persons förmåga att lösa utmaningar på bästa sätt. Dessutom är vi helt digitala, vilket möjliggör för oss att knyta kontakter runt om i hela Sverige. Vi värdesätter att ge frihet åt våra konsulter och att hjälpa dem uppnå sina mål i början på karriären. anställda 60+ Levererade projekt/år 100+ tech 100% Har du en idé? Berätta mer! Tjänster Menu Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning close Se mer Menu Kunder Om oss Karriär Kontakt Policy & Cookies close Kontakt hello@weknowit.se +46 (0) 8–194 811 Besök oss Kungsgatan 64 111 22 Stockholm We Know IT är techbolaget som sedan 2008 levererat innovativa plattformar och uppdrag inom utveckling, design och digital marknadsföring. Vi strävar efter långsiktiga samarbeten, leveranser över förväntan och ett agilt arbetssätt och kommunikation. © We Know IT Sweden AB close arrow-circle-o-down bars linkedin angle-down ellipsis-v instagram' metadata={'key': 'om-oss', 'url': 'https://www.weknowit.se/om-oss/', 'category': 'general'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Chunking the Text Content\n",
    "\n",
    "Now we move on to one of the most essential aspects of building a useful vector space: **chunking the documents**. There are several key considerations when chunking your data:\n",
    "\n",
    "- **Not too long**: Currently, the documents we have may vary significantly in length. We want a uniform representation of text in terms of size, as this increases the likelihood that information is evenly distributed across the dataset.\n",
    "- **Not too short**: If the chunks of text are too short, a specific chunk might not contain any relevant context. We need to ensure each chunk can hold valuable information relevant to a given query.\n",
    "- **Embedding models**: Many embedding models are trained with a specific chunk size in mind, optimizing them to build meaningful embeddings for chunks of that size. Simply put, we want the embedding model to excel at taking a query, building a vector representation, comparing it to vectors in our vector database, and returning relevant context. Some models even have a hard limit—if you try to embed text exceeding the preferred size, the model will simply truncate the text.\n",
    "\n",
    "Information about the configuration of embedding models can be found on the Hugging Face Massive Text Embedding Benchmark Leaderboard, or the MTEB Leaderboard: [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "\n",
    "#### Langchain Recursive Character Text Splitter\n",
    "\n",
    "While some applications may require more sophisticated approaches to chunking, such as hierarchical chunking, a simple character text splitter often suffices. In the declaration below, we specify that we want our chunks to be of size 512 tokens, with a chunk overlap of 30 tokens.\n",
    "\n",
    "**Why the chunk overlap?** Because we don't want to lose information. When we strictly cut the text at 512 tokens, it's possible that a sentence answering a specific query starts at the end of one chunk and finishes at the beginning of another. To preserve this semantic meaning, a good practice is to use an overlap of 30 tokens. This means that the last 30 tokens of chunk *n* are the same as the first 30 tokens of chunk *n + 1*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=30)\n",
    "chunked_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Unique identifiers\n",
    "To create a more meaningful ID than the index in the dataframe is good practice. Here, we previously introduced a `key`attribute based on the url. Now, we use that key along with a counter to idnetify the chunks.\n",
    "\n",
    "This means that the chunks will have IDs like \"karriar_0\", \"karriar_1\" and so on for each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_key = None\n",
    "counter = 0\n",
    "\n",
    "for chunk in chunked_docs:\n",
    "    key = chunk.metadata.get(\"key\")\n",
    "    if key != current_key:\n",
    "        current_key = key\n",
    "        counter = 0\n",
    "    chunk.metadata[\"chunk_id\"] = f\"{key}_{counter}\"\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - The embedding functions\n",
    "These are supporting functions, based on the already existing functions and methods on HuggingFace. It can be nice to write these manually in order to have more control of what we do with the text chunks. Referring to the HF documentation for full reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def doc_embedding(embedding_model: str, \n",
    "                  model_kwargs: dict={'device':'cpu'}, \n",
    "                  encode_kwargs: dict={'normalize_embeddings':True},\n",
    "                  cache_folder: Optional[str]=None,\n",
    "                  multi_process: bool=False\n",
    "                  ) -> HuggingFaceEmbeddings:\n",
    "    embedder = HuggingFaceEmbeddings(\n",
    "        model_name = embedding_model,\n",
    "        model_kwargs = model_kwargs,\n",
    "        encode_kwargs = encode_kwargs,\n",
    "        cache_folder = cache_folder,\n",
    "        multi_process = multi_process\n",
    "    )\n",
    "    return embedder\n",
    "\n",
    "def get_API_embedding(text, model):\n",
    "    embedder = doc_embedding(model)\n",
    "    embedding = embedder.embed_query(text)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 - Create the vector databases\n",
    "\n",
    "In order to do this, we need to download an embedding model. In this example, we download the model locally, since it is rather small. The task is then to use our created langchain Documents and the embedding model to locally persist a directory, which is the Chroma collection and the Chroma DB we will then use for context retrieval. More about Chroma in the README.md file.\n",
    "\n",
    "**NOTE**: The part commented out is what you would use when the embedding database is not yet built. In that version, we pass our chunked documents along with out embedding model and directory name to the `Chroma.from_documents`function. When this is already done, we simply load it from memory. I recommend you delete the collection and build it yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axelandersson/Desktop/github/wkit-chatbot/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/axelandersson/Desktop/github/wkit-chatbot/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "embedding_model = doc_embedding(model)\n",
    "\n",
    "persist_directory = \"e5_ml_db\"\n",
    "\n",
    "# vectordb = Chroma.from_documents(documents=chunked_docs, \n",
    "#                                  embedding=embedding_model, \n",
    "#                                  persist_directory=persist_directory)\n",
    "\n",
    "vectordb = Chroma(embedding_function=embedding_model, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7 - Context retrieval in action\n",
    "Now it is time to look at the retrieval process. We simply construct a query, and use the vectordb instance to perform a similarity search over our entire vector database (all the chunks we have built, each 512 tokens long), and we also state how many chunks we want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hur bygger We Know IT sina webbsidor?\"\n",
    "context = vectordb.similarity_search_with_relevance_scores(query, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell prints the documents found most similar towards the given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Nyfiken På We Know IT? | Om Oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Varför We Know IT? Vi är IT-konsultbolaget som satsar på studerande och nyexade talanger med höga ambitioner och drivkrafter.\\xa0Experter på utveckling, design och', metadata={'category': 'general', 'chunk_id': 'om-oss_0', 'key': 'om-oss', 'url': 'https://www.weknowit.se/om-oss/'}),\n",
       "  0.6072708608347592),\n",
       " (Document(page_content='Karriar | We Know IT Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Bli en del av vår framgångssaga. Vi har anställningsmöjligheter som passar alla, vare sig du söker heltid, deltid eller frilansarbete. Lediga tjänster Spontanansökan', metadata={'category': 'general', 'chunk_id': 'karriar_0', 'key': 'karriar', 'url': 'https://www.weknowit.se/karriar/'}),\n",
       "  0.5878009977246061),\n",
       " (Document(page_content='Webbutveckling För Företag & Organisationer | We Know IT Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Webbutveckling. För oss på We Know IT är webbsidor och digitala plattformar mer än bara kod – de är affärskritiska gränssnitt som', metadata={'category': 'services', 'chunk_id': 'webbutveckling_0', 'key': 'webbutveckling', 'url': 'https://www.weknowit.se/tjanster/webbutveckling/'}),\n",
       "  0.5800885037687491),\n",
       " (Document(page_content='av en webbsida eller ett element för att se vilket som presterar bättre. Genom att använda verktyg för webbanalys kan marknadsförare få insikter om användarbeteende, vilka sidor som presterar bra och vilka som har hög avvisningsfrekvens, vilket möjliggör datadrivna beslut för att förbättra konverteringsfrekvensen. Innovativa projektexempel. Folkes Biluthyrning Digitalisering av biluthyrning med webbsida och integrerat bokningssystem. Boujt Webbsida med chatfunktion med text eller video, inloggning och', metadata={'category': 'services', 'chunk_id': 'digital-marknadsforing_15', 'key': 'digital-marknadsforing', 'url': 'https://www.weknowit.se/tjanster/digital-marknadsforing/'}),\n",
       "  0.5758030122121615),\n",
       " (Document(page_content='en effektiv utvecklingsfas av webbsidan. Vi använder vårt unika ramverk för att säkerställa högsta kvalitet och kontinuerlig rapportering. 5. Innehåll I samband med webbutveckling uppstår ofta behovet av nytt innehåll. Vi lägger stor vikt vid att SEO-anpassa alla texter i termer av sökordsdensitet, ordmängd och kvalitet. 6. Kvalitetssäkring & lansering När webbutvecklingen är färdig och det nya innehållet har integrerats är det dags för det avslutande sluttestet av webbplatsen. Vi följer noggrant ett', metadata={'category': 'services', 'chunk_id': 'webbutveckling_16', 'key': 'webbutveckling', 'url': 'https://www.weknowit.se/tjanster/webbutveckling/'}),\n",
       "  0.5522240421064388)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8 - Chatbot in action\n",
    "This part requires that you create a `.env` file in the root directory, and that you insert the following line:\n",
    "\n",
    "OPENAI_KEY=<your_generated_key>\n",
    "\n",
    "You can generate your API key here: https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Retrieve the value of the environment variable\n",
    "openai_key = os.environ.get(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a GPT-3.5 instance\n",
    "This is a simple way to load a 3.5 instance using your API key. We set temperature to 0.1, which can be seen as the freedom the model has to generate creative responses. If temperature = 0, it is very strict and will likely yield the same response to a given query at any time. Temperature = 1 will yield a model prone to hallucinations, often generating strange and incorrect responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(\n",
    "    openai_api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our first RAG chain!\n",
    "Now, we set up a very simple structure in order to answer questions. The following can be said about this code cell:\n",
    "\n",
    "- **System prompt**: A system prompt is a OpenAI specific terminology, but corresponding functionality exists for all LLMs. The idea is that the  models are trained to accept a system prompt that contextualizes what we try to achieve and acts as general guidelines for the model. \n",
    "- **Function for get_prompt**: Here, we perform the same context retrieval we did earlier, but we do some preprocessing to construct a nice readable prompt. We simply extract the page content of each chunk and separate them by a new line.\n",
    "- **Final simple RAG prompt**: The last part of the cell just states that the model shall amswer a question, the `query` passed to the function, and it shall use the `context`, the merged page_content from our retrieved chunks, to answer it. This is in all its simplicity what Retreival Augmented Generation is.\n",
    "\n",
    "**NOTE** that this is just the simplest of examples. This is where you can get creative. You can prompt the model to generate responses in any way or format you like, you can include metadata filtering to find information easier, or maybe use metadata in the response to for example link to the source of information using the URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (SystemMessage, HumanMessage, AIMessage)\n",
    "\n",
    "system_prompt = \"\"\"Du är en hjälpsam AI assistent, specialiserad på att svara på frågor om ett IT-konsultbolag som\n",
    "                heter We Know IT. Du kommer att få frågor samt utvald information, vilken du kan använda\n",
    "                för att svara på frågan. Svara på svenska.\"\"\"\n",
    "\n",
    "def get_prompt(query: str, vectordb):\n",
    "    # Retrieve 10 chunks with relevance scores\n",
    "    context_results = vectordb.similarity_search_with_relevance_scores(query, 10)\n",
    "    \n",
    "    # Extract the page_content from each context document\n",
    "    context = \"\\n\".join([doc.page_content for doc, score in context_results])\n",
    "    \n",
    "    # Construct the final prompt\n",
    "    user_prompt = f\"\"\"Svara på följande fråga: {query}.\n",
    "\n",
    "Du kan använda följande information för att generera ditt svar:\n",
    "{context}\"\"\"\n",
    "\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svara på följande fråga: Hur bygger We Know It sina webbapplikationer?.\n",
      "\n",
      "Du kan använda följande information för att generera ditt svar:\n",
      "av en webbsida eller ett element för att se vilket som presterar bättre. Genom att använda verktyg för webbanalys kan marknadsförare få insikter om användarbeteende, vilka sidor som presterar bra och vilka som har hög avvisningsfrekvens, vilket möjliggör datadrivna beslut för att förbättra konverteringsfrekvensen. Innovativa projektexempel. Folkes Biluthyrning Digitalisering av biluthyrning med webbsida och integrerat bokningssystem. Boujt Webbsida med chatfunktion med text eller video, inloggning och\n",
      "Webbutveckling För Företag & Organisationer | We Know IT Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Webbutveckling. För oss på We Know IT är webbsidor och digitala plattformar mer än bara kod – de är affärskritiska gränssnitt som\n",
      "Nyfiken På We Know IT? | Om Oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Varför We Know IT? Vi är IT-konsultbolaget som satsar på studerande och nyexade talanger med höga ambitioner och drivkrafter. Experter på utveckling, design och\n",
      "Karriar | We Know IT Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Bli en del av vår framgångssaga. Vi har anställningsmöjligheter som passar alla, vare sig du söker heltid, deltid eller frilansarbete. Lediga tjänster Spontanansökan\n",
      "en effektiv utvecklingsfas av webbsidan. Vi använder vårt unika ramverk för att säkerställa högsta kvalitet och kontinuerlig rapportering. 5. Innehåll I samband med webbutveckling uppstår ofta behovet av nytt innehåll. Vi lägger stor vikt vid att SEO-anpassa alla texter i termer av sökordsdensitet, ordmängd och kvalitet. 6. Kvalitetssäkring & lansering När webbutvecklingen är färdig och det nya innehållet har integrerats är det dags för det avslutande sluttestet av webbplatsen. Vi följer noggrant ett\n",
      "Apputveckling | Vi Bygger Er App | We Know IT Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital marknadsföring Hosting & förvaltning Om oss Karriär Kontakta oss Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriar Kontakta oss Apputveckling. I en värld där appar dominerar varje telefon, förstår vi vikten av kvalitet och räckvidd. Med vår expertis i kostnadseffektiv\n",
      "att växa ytterligare. De automatiseringar som är utvecklade och integrerade i systemen har också förbättrat och förenklat kommunikationen med kunder, samtidigt som kundkapaciteten blivit högre. Parallellt har vi jobbat med digital marknadsföring i form av Google Ads. Det är en insats som har genererat bättre synlighet, fler kunder och ett starkare varumärke. Har du en idé? Berätta mer! Tjänster Menu Konsultuthyrning Webbutveckling Apputveckling UX/UI - Design Digital Marknadsföring Hosting & Förvaltning\n",
      "er professionella image. Genom att skapa en översiktlig och engagerande portfölj, kan ni effektivt visa upp er kompetens och locka intresse från potentiella kunder eller samarbetspartners. Innovativa projektexempel. Folkes Biluthyrning Digitalisering av biluthyrning med webbsida och integrerat bokningssystem. Boujt Webbsida med chatfunktion med text eller video, inloggning och teckenspråkstolkat innehåll. AI Medical Technology Webbsida med produktinformation om en AI applikation. Världskulturmuseet\n",
      "Webbutveckling Världskulturmuseet | Kundcase Av We Know IT Våra kunder Våra tjänster Om oss Karriär Kontakta oss Kontakta oss Konsultuthyrning Webbutveckling Apputveckling UX/UI-Design Digital marknadsföring Hosting & Förvaltning Cases Våra tjänster Om oss Karriär Kontakta oss Kontakta oss Starta projekt Starta projekt Våra kunder Våra tjänster Konsultuthyrning Webbutveckling Apputveckling Design Digital Marknadsföring Hosting & Förvaltning Om oss Karriär Kontakt Världskulturmuseet Världskulturmuseet i\n",
      "besökare på en webbplats som utför en önskad handling, såsom att göra ett köp, registrera sig för ett nyhetsbrev eller fylla i ett kontaktformulär. Genom att fokusera på att förbättra användarupplevelsen och ta bort hinder som kan hindra konvertering, kan företag öka sin effektivitet online och få ut mer av sin befintliga trafik utan att nödvändigtvis öka budgeten för att locka fler besökare. Konverteringsoptimering innebär en systematisk process av testning och analys, där olika element på webbplatsen\n"
     ]
    }
   ],
   "source": [
    "test = get_prompt(\"Hur bygger We Know It sina webbapplikationer?\", vectordb)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we finally put everything together and ask our RAG system a question about We Know IT!\n",
    "\n",
    "As you can see by the response, we have utilized the GPT models ability to generate fluent and nice tetual content but we provide it with our data in an effective way. This response is certainly nothing a good ol' GPT knows by heart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We Know IT bygger sina webbapplikationer genom en effektiv utvecklingsfas av\n",
      "webbsidan. De använder sitt unika ramverk för att säkerställa högsta kvalitet\n",
      "och kontinuerlig rapportering. Vidare lägger de stor vikt vid att SEO-anpassa\n",
      "allt innehåll i termer av sökordsdensitet, ordmängd och kvalitet. När\n",
      "webbutvecklingen är färdig och det nya innehållet har integrerats, genomförs\n",
      "kvalitetssäkring och lansering av webbplatsen. We Know IT fokuserar också på\n",
      "konverteringsoptimering för att förbättra användarupplevelsen och öka\n",
      "effektiviteten online.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "query = \"Hur bygger We Know It sina webbapplikationer?\"\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=get_prompt(query, vectordb))\n",
    "]\n",
    "response = chat_model.invoke(messages)\n",
    "wrapped_response = textwrap.fill(response.content, width=80)\n",
    "print(wrapped_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to API Calls...\n",
    "Now, we look at the RAG.py script that spins up a FastAPI endpoint for our RAG system. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
